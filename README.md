# Enhanced Entertainment Industry Electric Chainhoist Database v2.0

ðŸ—ï¸ **A comprehensive, production-ready database system for electric chainhoists used in the entertainment industry**

[![Tests](https://github.com/DGProject2030/datascrapper/actions/workflows/test.yml/badge.svg)](https://github.com/DGProject2030/datascrapper/actions/workflows/test.yml)
[![codecov](https://codecov.io/gh/DGProject2030/datascrapper/branch/master/graph/badge.svg)](https://codecov.io/gh/DGProject2030/datascrapper)
[![Version](https://img.shields.io/badge/version-2.0.0-blue.svg)](https://github.com/DGProject2030/datascrapper)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Node.js](https://img.shields.io/badge/node-%3E%3D16.0.0-brightgreen.svg)](https://nodejs.org/)

## ðŸš€ What's New in v2.0

- **REST API** - Full programmatic access with comprehensive endpoints
- **Advanced Validation** - Enhanced data quality assurance and error handling
- **Performance Optimization** - Caching, backup systems, and improved processing
- **Configuration Management** - Centralized config with environment support
- **Enhanced UI** - Modern responsive interface with better search capabilities
- **Export Formats** - Multiple export options (JSON, CSV, Excel, PDF)
- **Comprehensive Logging** - Detailed logging and statistics tracking

## ðŸ“‹ Table of Contents

- [Features](#-features)
- [Quick Start](#-quick-start)
- [Installation](#-installation)
- [Usage](#-usage)
- [Testing](#-testing)
- [API Documentation](#-api-documentation)
- [Project Architecture](#-project-architecture)
- [Configuration](#-configuration)
- [Data Structure](#-data-structure)
- [Contributing](#-contributing)
- [License](#-license)

## âœ¨ Features

### ðŸ•·ï¸ **Enhanced Data Scraper**
- Multi-manufacturer support (Columbus McKinnon, Chainmaster, Verlinde, Movecat, GIS AG)
- Intelligent error handling and retry mechanisms
- Data validation and quality assurance
- Caching system for improved performance
- Configurable delays and concurrent processing
- Automated backup and recovery

### ðŸ”§ **Advanced Data Processor**
- Unit conversion and standardization
- Classification normalization (D8, D8+, BGV-C1)
- Duplicate detection and merging
- Data completeness analysis
- Quality reporting and statistics
- Enhanced field mapping and validation

### ðŸŒ **Modern Web Interface**
- Responsive design with Bootstrap 5
- Advanced search and filtering
- Product comparison tools
- Visual statistics and charts
- Mobile-friendly interface
- Real-time data updates

### ðŸ”Œ **RESTful API**
- Full CRUD operations
- Advanced search capabilities
- Pagination and sorting
- Rate limiting and security
- Comprehensive documentation
- JSON response format

## ðŸš€ Quick Start

```bash
# Clone the repository
git clone https://github.com/yourusername/chainhoist-database.git
cd chainhoist-database

# Install dependencies
npm install

# Run the complete pipeline
npm run build && npm start
```

Visit `http://localhost:3000` for the web interface or `http://localhost:3000/api` for API documentation.

## ðŸ“¦ Installation

### Prerequisites
- **Node.js** >= 16.0.0
- **NPM** >= 8.0.0
- **Modern web browser** (Chrome, Firefox, Safari, Edge)

### Step-by-Step Installation

1. **Download the project files** to your local machine
2. **Navigate to the project directory**
   ```bash
   cd chainhoist-database
   ```
3. **Install dependencies**
   ```bash
   npm install
   ```
4. **Verify installation**
   ```bash
   npm run stats
   ```

## ðŸ“– Usage

### Data Collection
Scrape chainhoist data from manufacturer websites:
```bash
npm run scrape
```

This creates a `chainhoist_data` directory with raw scraped data in JSON and CSV formats.

### Data Processing
Clean, normalize, and enhance the collected data:
```bash
npm run process
```

Processes all records and exports to `chainhoist_data_processed` directory with:
- Normalized specifications (load capacities, speeds, power ratings)
- Standardized terminology and classifications
- Data quality reports
- Enhanced metadata

### Web Interface
Start the web-based database viewer:
```bash
npm start
# or
npm run serve
```

The application will be available at `http://localhost:3000`

### Complete Pipeline
Execute the entire workflow:
```bash
npm run build && npm start
```

## ðŸ§ª Testing

This project uses **Jest** and **Supertest** for testing the API endpoints.

### Running Tests

```bash
# Run all tests
npm test

# Run tests with coverage report
npm run test:coverage
```

### Test Coverage

Current coverage metrics:
- **Statements:** ~50%
- **Branches:** ~28%
- **Functions:** ~56%
- **Lines:** ~53%

Coverage reports are generated in the `coverage/` directory with HTML reports viewable at `coverage/lcov-report/index.html`.

### Test Structure

```
__tests__/
â””â”€â”€ api.test.js    # API endpoint tests (24 tests)
```

### Test Suites

| Suite | Tests | Description |
|-------|-------|-------------|
| API Documentation | 1 | Verifies `/api` returns docs |
| GET /api/chainhoists | 7 | List, pagination, filtering |
| GET /api/chainhoists/:id | 2 | Get by ID, 404 handling |
| GET /api/manufacturers | 2 | Manufacturer statistics |
| GET /api/classifications | 2 | Classification counts |
| GET /api/stats | 2 | Database statistics |
| POST /api/search | 6 | Advanced search |
| Error Handling | 2 | Invalid parameter handling |

### Continuous Integration

This project uses **GitHub Actions** for automated testing:

- Tests run automatically on every push to `master`/`main`
- Tests run on all pull requests
- Tests against Node.js 18.x and 20.x
- Coverage reports uploaded to Codecov

View CI status: [GitHub Actions](https://github.com/DGProject2030/datascrapper/actions)

## ðŸ”Œ API Documentation

### Base URL
```
http://localhost:3000/api
```

### Authentication
No authentication required (public API)

### Endpoints

#### Get All Chainhoists
```http
GET /api/chainhoists
```

**Query Parameters:**
- `manufacturer` - Filter by manufacturer name
- `model` - Filter by model name  
- `classification` - Filter by classification (d8, d8+, bgv-c1)
- `minCapacity` - Minimum load capacity in kg
- `maxCapacity` - Maximum load capacity in kg
- `page` - Page number (default: 1)
- `limit` - Results per page (default: 50, max: 100)

**Example:**
```bash
curl "http://localhost:3000/api/chainhoists?manufacturer=Columbus%20McKinnon&minCapacity=500"
```

#### Get Specific Chainhoist
```http
GET /api/chainhoists/:id
```

#### Advanced Search
```http
POST /api/search
Content-Type: application/json

{
  "query": "lodestar",
  "capacityRange": { "min": 250, "max": 1000 },
  "manufacturers": ["Columbus McKinnon", "Chainmaster"],
  "classifications": ["d8", "d8+"],
  "sortBy": "loadCapacity",
  "sortOrder": "desc"
}
```

#### Get Manufacturers
```http
GET /api/manufacturers
```

**Response:**
```json
{
  "success": true,
  "data": [
    { "name": "Columbus McKinnon", "count": 45, "models": 12 },
    { "name": "Chainmaster", "count": 32, "models": 8 }
  ]
}
```

#### Get Classifications
```http
GET /api/classifications
```

**Response:**
```json
{
  "success": true,
  "data": [
    { "name": "d8", "count": 85 },
    { "name": "d8+", "count": 42 },
    { "name": "bgv-c1", "count": 38 }
  ]
}
```

#### Get Statistics
```http
GET /api/stats
```

**Response:**
```json
{
  "success": true,
  "data": {
    "totalRecords": 150,
    "manufacturers": 5,
    "classifications": 3,
    "capacityRange": { "min": 125, "max": 5000 },
    "dataCompleteness": {
      "loadCapacity": 0.95,
      "liftingSpeed": 0.87,
      "motorPower": 0.72
    }
  }
}
```

### Response Format
```json
{
  "success": true,
  "data": [...],
  "pagination": {
    "page": 1,
    "limit": 50,
    "total": 150,
    "pages": 3
  }
}
```

### Error Responses
```json
{
  "success": false,
  "error": "Error description",
  "message": "Detailed error message"
}
```

| Status Code | Description |
|-------------|-------------|
| 200 | Success |
| 404 | Resource not found |
| 500 | Internal server error |

## ðŸ—ï¸ Project Architecture

The project follows a modular architecture separating concerns for better testability and maintainability.

### File Structure

```
datascrapper/
â”œâ”€â”€ app.js                      # Express app configuration & routes (testable)
â”œâ”€â”€ server.js                   # Server startup (imports app.js)
â”œâ”€â”€ chainhoist-scraper.js       # Data collection from manufacturers
â”œâ”€â”€ chainhoist-data-processor.js # Data cleaning & normalization
â”œâ”€â”€ export-tools.js             # Export utilities (CSV, JSON, Excel, PDF)
â”œâ”€â”€ config.json                 # Application configuration
â”œâ”€â”€ package.json                # Dependencies & scripts
â”œâ”€â”€ __tests__/
â”‚   â””â”€â”€ api.test.js             # API test suite
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ test.yml            # GitHub Actions CI/CD
â”œâ”€â”€ views/                      # EJS templates
â”œâ”€â”€ chainhoist_data/            # Raw scraped data
â””â”€â”€ chainhoist_data_processed/  # Processed database
```

### Key Components

| File | Purpose |
|------|---------|
| `app.js` | Express application with all routes. Exported for testing. |
| `server.js` | Server startup, template initialization. Imports `app.js`. |
| `chainhoist-scraper.js` | Web scraper for manufacturer data |
| `chainhoist-data-processor.js` | Data normalization and quality checks |
| `export-tools.js` | Multi-format export utilities |

### Design Decisions

- **Separated `app.js` from `server.js`** - Allows importing Express app for testing without starting server
- **Modular scrapers** - Each manufacturer can have custom extraction logic
- **JSON data storage** - Simple, portable, no database setup required
- **EJS templating** - Server-side rendering for web interface

## âš™ï¸ Configuration

### Configuration File
Edit `config.json` to customize behavior:

```json
{
  "scraper": {
    "requestDelay": 2000,
    "maxRetries": 3,
    "enableCache": true,
    "validateData": true
  },
  "viewer": {
    "port": 3000,
    "enableAPI": true
  }
}
```

### Environment Variables
```bash
PORT=3000                    # Server port
LOG_LEVEL=info              # Logging level
NODE_ENV=development        # Environment
CACHE_ENABLED=true          # Enable caching
```

## ðŸ“Š Data Structure

### Chainhoist Record Schema

```typescript
interface Chainhoist {
  // Identification
  id: string;
  manufacturer: string;
  model: string;
  series?: string;
  
  // Technical Specifications
  loadCapacity?: string;      // "500 kg (1100 lbs)"
  liftingSpeed?: string;      // "4 m/min (13 ft/min)"
  motorPower?: string;        // "1.1 kW (1.5 HP)"
  dutyCycle?: string;
  voltageOptions?: string[];
  
  // Physical Characteristics
  weight?: string;
  dimensions?: string;
  noiseLevel?: string;
  
  // Entertainment Industry Specifics
  classification?: string[];   // ["d8", "bgv-c1"]
  quietOperation?: boolean;
  dynamicLifting?: boolean;
  liftingOverPeople?: boolean;
  
  // Safety Features
  upperLimitSwitch?: string;
  lowerLimitSwitch?: string;
  overloadProtection?: string;
  emergencyStop?: string;
  
  // Commercial Information
  price?: { value: number, currency: string };
  warranty?: string;
  leadTime?: string;
  
  // Metadata
  url?: string;
  datasheet?: string;
  images?: string[];
  lastUpdated: Date;
  confidence: number;         // Data quality score (0-1)
}
```

### Classification Standards

- **D8** - Standard entertainment industry classification
- **D8+** - Enhanced D8 with additional safety features
- **BGV-C1** - German professional stage equipment standard
- **ANSI** - American National Standards Institute compliance

## ðŸ› ï¸ Development

### Available Scripts

| Command | Description |
|---------|-------------|
| `npm run scrape` | Run data scraper |
| `npm run process` | Process scraped data |
| `npm run serve` | Start web server |
| `npm run build` | Complete pipeline (scrape + process) |
| `npm start` | Start web server (production) |
| `npm run dev` | Development mode |
| `npm test` | Run test suite |
| `npm run test:coverage` | Run tests with coverage report |
| `npm run validate` | Validate database integrity |
| `npm run stats` | Generate statistics report |
| `npm run export:csv` | Export database to CSV |
| `npm run export:json` | Export database to JSON |

### Adding New Manufacturers

1. Edit `chainhoist-scraper.js`
2. Add manufacturer configuration to the `manufacturers` array:

```javascript
{
  name: 'Manufacturer Name',
  baseUrl: 'https://manufacturer.com',
  startUrls: ['https://manufacturer.com/products'],
  productListSelector: '.product-list a',
  dataExtractors: {
    model: { selector: '.product-title', transform: (text) => text.trim() },
    // Add more extractors...
  }
}
```

### Database Fields

To add or modify database fields:

1. Update the `SCHEMA` object in `chainhoist-data-processor.js`
2. Add corresponding extractors in the scraper
3. Update viewer templates in the `views` directory

## ðŸ“ˆ Performance

### Optimization Features

- **Caching System** - Reduces redundant requests
- **Database Indexing** - Fast lookups and searches
- **Pagination** - Efficient large dataset handling
- **Compression** - Reduced network overhead
- **Rate Limiting** - API protection and stability

### Benchmarks

- **Scraping Speed** - ~100 products/minute (with 2s delay)
- **API Response Time** - <100ms for typical queries
- **Database Size** - Supports 10,000+ records efficiently
- **Memory Usage** - <100MB typical operation

## ðŸ”’ Security

### Implemented Security Measures

- **Rate Limiting** - Prevents API abuse
- **Input Validation** - Protects against injection attacks
- **CORS Configuration** - Cross-origin request control
- **Helmet.js** - Security headers
- **Error Handling** - No sensitive data exposure

## ðŸ¤ Contributing

We welcome contributions! Here's how you can help:

### Priority Areas
1. **New Manufacturer Support** - Add more chainhoist manufacturers
2. **Data Accuracy** - Improve extraction and validation
3. **UI/UX Enhancement** - Better user interface design
4. **API Features** - Additional endpoints and functionality
5. **Test Coverage** - Increase test coverage above 80%
6. **Documentation** - Improve guides and examples

### Contribution Process
1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

### Development Guidelines
- Follow existing code style
- Add comments for complex logic
- Update documentation for new features
- Test thoroughly before submitting

## ðŸ“Š Future Enhancements

### Planned Features
- **User Accounts** - Personal collections and preferences
- **Advanced Analytics** - Market trends and insights
- **Mobile App** - Native mobile application
- **Inventory Integration** - Rental company integration
- **PDF Exports** - Professional reports and catalogs
- **Multi-language** - International language support

## ðŸ› Troubleshooting

### Common Issues

**Issue: "Cannot find module" errors**
```bash
# Solution: Reinstall dependencies
rm -rf node_modules package-lock.json
npm install
```

**Issue: Port 3000 already in use**
```bash
# Solution: Use different port
PORT=3001 npm start
```

**Issue: Scraping fails with timeout errors**
```bash
# Solution: Increase timeout in config.json
"timeout": 60000  // 60 seconds
```

### Getting Help

1. Check the troubleshooting section above
2. Review the [API documentation](http://localhost:3000/api)
3. Submit an issue on GitHub with:
   - Error message and stack trace
   - Steps to reproduce
   - System information (OS, Node.js version)

## ðŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ðŸ™ Acknowledgments

- **Entertainment Industry** - For safety standards and classifications
- **Manufacturer Websites** - Data sources (used respectfully)
- **Open Source Community** - Libraries and tools used
- **Contributors** - Everyone who helped improve this project

---

**Disclaimer:** This database is for informational purposes only. Always consult manufacturer specifications and current safety standards for critical applications. The maintainers assume no responsibility for the accuracy or completeness of the data.

**Copyright Â© 2024 DataScrapper Enhanced. All rights reserved.**